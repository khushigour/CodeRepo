
MPP- massive parallel processing technology/framework

Advantage of MR:
> Cluster monitoring
> resource allocation (RAM needed ?)
> cluster management (what if node goes down)
> Scheduling
> Execution
> Speculative execution (L)

Aim of MR: to achieve data locality
To identify which machine/datanode has the particular required
block and in that task should be executed

Daemons in MR: Jobtracker and Tasktracker - v1
Resource manager and node manager - v2


MAP (parallelism )-> REDUCE (combine back)
EXAMPLE:
           Single process = 1 Teacher (/core)
           Task: find topper for state
           Paper checking speed for 1 teacher = 1min/paper
           Total time = 20 min

           IIel processing = 4 teacher
           Task: find topper for state

           5 mins taken as divided in 4 teacher to get topper from 4 teachers (say at district level)
           now reducer: one final topper found from these 4 toppers (at state level)

           MAP:  T1   T2   T3   T4 - > 5 MINS

           REDUCE: FINAL_TOPPER   -> 4 MINS
           Total time = 9 mins


Different Java code for mapper side and reducer side

MAPPER:
Input  = Blocks
Stored = HDFS, can read from local, rdms, or other file system (batch not streaming ones like kafka)

REDUCER:
Input = map output
Store = HDFS, NOSQL, RDMS...

MAP - MAP - REDUCE : possible
MAP - REDUCE - REDCUE :  not possible ( possible in spark)

No of Blocks  = No of mapper (by default)
No of reducer = decided by developer

> ARCHITECTURE 1
- convert Java into jar file then execute ( container mapper and reducer class)
- deamon JT ---request---> namenode ---response---> (metadata)
- assign task to TaskTracker
- launch map JVM (parallely)
- INTERMIDIATE DATA - output of mapper stored in : local file system of node | spark has option to store in memory
- TaskTracker also sends heartbeat to JobTracker
- Reducer Task starts, Reduce jvm: JT informs Mapper nodes to transfer output to reducer node via HTTP protool
- This gets stored in local file system, then HDFS
- In between execution in one datanode, the node went down then whole job wont be killed only this task will be restarted (get 2nd copy info from metadata and start task in that node)
CASE: say 2 diff blocks of same file present in same node, then how processing happens ?
- Whenever request comes from job tracker it spans to 2 mapper jvm and 2 reducer jvm (Execution happems parallely within the node also)
- If other blocks present then others will be in queue or we can increase threads | we cannot achieve 100% parallelism cause we don't know whic block present in which node. 
s

MAPPER & REDUCER INPUT/OUTPUT FORMAT:

-> Always key-value pair
->1) Text input & Text Output: key = offset(starting position of the record) of record, value = whole line of the record
->2) Key value input & output format : upto 1st delimiter (tab)


HOW DATA FLOWS:
CASE: 
    - 1, amazon, mobile, 2000
B0  | 2, amazon, TV, 1000
    - 3, flipkart, AC, 3000
    - 4, flipkart, washington, 5000
B1  | 5, amazon, cycle, 5500
    | 6, ebay, watvh, 7800
    - 7, flipkart, laptop, 9800

Select the column (in mapper side)
shuffle - sort group by
interating and sum (not over records, but over list within record)

DATATYPES:


ARCHITECTURE 2:

       MR SPARK HBASE STORM
    ----------------------------
                YARN - cluster manager gives common execution model for any stack run on top of it
    -----------------------------
                HDFS



