Hadoop -> HDFS + MapReduce

File System :  NTFS(Windows), EXT (Linux), HDFS, S3(AWS objects)
-> used to read and write from and to HardDrive
    |
    v
 ---FS----   OS
    HD

BLOCK: fs split data into small chunks

NTFS: 16kb, ext : 512kb

Types of file System: Standalone, distributes

    1 <---> 2  <--> 3

    DE: Data should be distributed within clusters
    N/W: topology of infrastructure

Types of distributed:
1. Master - slave :  hadoop, spark
   Disadvantages
   SPOS: Single point of Source, any node down only master knows
   due to SPOC: Single Point of Communication
2. peer to peer : each node is connected to/know the status of other node
   EX: Cassandra

Program in execution is process
Background process for each process -  daemon process
example: hadoop is a process for which there are 5 deamon processes (3 hdfs, 2 mp)

node - individual machine
cluster - group of nodes

block size in hdfs: 1B = 64MB (hadoop 1), 1B = 128MP (later versions)

Replication: no of copies for block
say storing 1gb data, say divided into 4 blocks and replication factor =3
                n1    n2   n3
                b1    b2   b3
                b4    b1   b2
                b2    b3   b4
                b3    b4   b1



Edge node: developers don't directly connect to master or cluster node for read write ( to trigger any hadoop jobs, mapreduce jobs, spark jobs...)

> READ-WRITE algo :

Suppose you are make write request to one node,
then one client-ap is created which redirects the request to Master node
Only info about data, is send to master (not the actual data)
Master daemon will create meta-data:
1. file size (say 1gb) , block size (default 64mb) = number of blocks = 1000/64
2. Replication for each block
3. placement for each block (Rack awareness policy algorithm)

This meta-data is stored in ext of master machine.

> Client-api will create a pipeline, it will distribute the data:

For example:
    B0B1B2.....B12B13B14B15
    B0B0BO.....B14B15B15B15 (after replication, Rf = 3)
    1 2 3          2  3 4   (placement)
                  n1 (master node)

       n2     n3      n4      n5
   -->B0..
             B0..B15
                      B0..B15
                               ..B15

After this each node sends a confirmation/acknowledgement that block is written successfully:
then pipeline will confirm client api :
then master knows successfull write happended

For every 3 sec slave will communicate to master (heartbeat communication)
Master this way will know which node is alive

Failure: Network | software ,  hardware issue

1. say node4 is dead, automatic failover : again hadoop will try to get 3 as replication factor
2. say 2 nodes go down, hadoop will try to do automatic failover
 but since only 2 nodes are available it will have the data in those 2, can't maintain rf =3
3. suggestion: make a failure as permanent one by removing the node and adding new one

4. Case:
   nodes   n1      n2      n3      n4
                   Fail
           B0      B0B15   B0B15    B15

 Say n2 fails so and B0 gets replicated to n4 : meta data got updated,
but in the meantime n2 is alive again then B15 wont be replicated. Now as per
meta data B0 is available in n1,n3,n4 so we only will have to clear BO present
in n2. Hence better to make it a permanent failure and remove n2 itself.

5. Case: Failure during write,

6. Your read and write request wont fail in any case though apart from these 2:
 > all nodes are down
 > client api itself is down/failed

JP1 - namenode, JP2 - datanode, JP3 - secondary namenode
JP4 - job tracker(1) / resource manager (2), JP5 - task tracker (1)/ node manager (2)

HA: High Availability
> if master node gets down, everything is gone as meta data will be gone (if permanent failure)

Hence extra hard-drive copies are made at some interval of masternode, but this issue is resolved in later versions

READ: request goes to client api, which sends to master and then meta data is recieved and then
client api directly contact the desired node to get data


Hadoop2 version - more than one namenode / one Active(ANN) possible , others Passive(PNN)
  n1 n2 n3 - namenodes
  slave: n4 n5 n6 - datanodes ( heartbeat send to all namenodes)
Zookeeper : cluster coordinator technology, monitors all namenode /  elects namenode
(LEADER & FOLLOWER sturcture) zookeeper itself is a cluster with 1 leader and some followers
If leader goes down, other follower is elected as leader and namenodes are monitored by the new elected one now.

TYPES OF NODES:
   Hadoop1
 > masternode - NN + JT
 > slave node - DN + TT
 > checkpointnode - SNN

 Hadoop2 (without HA)
 > masternode - NN +RM
 > slavenode - DN + NM
 > SNN

 Hadoop2 (with HA)
 ANN+ARM PNN+PRM
 ZK ZK ZK - zookeeper nodes
 JN JN JN - to store meta data in sharding
 DN+NM DN+NM DN+NM


 Types of CLUSTER:
 1. Single Node (Psuedo Node Cluster)
  All in one: nn + rm + dn + Nm + snn
 2. Distributed
        | nm + rm |
        | snn |
        | dn + Nm |


> Hadoop framework :    Loosely coupled framework

Abstraction of Mapreduce: these 4
                 query engine                               data pipeline rdms only     (scheduler)
            hive(sql -> java mpr) , pig (piglatin) , sqoop (commands, data import-export), oozy (xml)
             -------------------------------------------------------------------------------
  |  HBASE  |                               MR
  Hbase shell
   commands    
             -------------------------------------------------------------------------------
     NOSQL            HDFS - shell commands to distribute data


Flume - connect with rdms also, also messaging queue (only retrieve data to hadoop not reverse)
Mahaut - ML related stuFF
